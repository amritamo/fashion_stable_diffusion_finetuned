{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnfaJK7g-r2c",
        "outputId": "014e08e3-359c-4bb1-c7c1-0ab3a03db4bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',  force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBY7oK5s-vnz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/stable-diffusion-keras-ft')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfZPxqbjBPU-"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets diffusers transformers accelerate torchmetrics[image]"
      ],
      "metadata": {
        "id": "tvbE9GuWDpkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJsosZlp-1-_"
      },
      "outputs": [],
      "source": [
        "from textwrap import wrap\n",
        "import os\n",
        "\n",
        "import keras_cv\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "# import tensorflow.experimental.numpy as tnp\n",
        "from keras_cv.models.stable_diffusion.clip_tokenizer import SimpleTokenizer\n",
        "from keras_cv.models.stable_diffusion.diffusion_model import DiffusionModel\n",
        "from keras_cv.models.stable_diffusion.image_encoder import ImageEncoder\n",
        "from keras_cv.models.stable_diffusion.noise_scheduler import NoiseScheduler\n",
        "from keras_cv.models.stable_diffusion.text_encoder import TextEncoder\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xdnqv393CEYj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from scipy.linalg import sqrtm\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMFVoPjCFrpB"
      },
      "outputs": [],
      "source": [
        "a = pd.read_csv(os.path.join('resize_imgs', \"data.csv\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python finetune_c.py --img_height 256 --img_width 256 --batch_size 3 --num_epochs 5 --ema 0 --lr 5e-05 --augmentation --lora --lora_rank 4 --lora_alpha 8 --mp --pretrained_ckpt \"b3_rank4_lr5e05/ckpt_batch_3_lora_4_lr_5e-05_epochs_10_res_256_mp_False.h5\""
      ],
      "metadata": {
        "id": "2LPhfgQhTX9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "h0RX82EgVtrf"
      },
      "outputs": [],
      "source": [
        "!python finetune_c.py --img_height 256 --img_width 256 --batch_size 6 --num_epochs 10 --ema 0 --lr 5e-05 --augmentation --lora --lora_rank 4 --lora_alpha 8 --mp --pretrained_ckpt  \"ckpt_batch_6_lora_4_lr_5e-05_epochs_8_res_256_mp_False.h5\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3J49ZRAJYjEg"
      },
      "outputs": [],
      "source": [
        "!python finetune_c.py --img_height 256 --img_width 256 --lr 1e-4 --ema 0 --num_epochs 2 --lora --lora_rank 22 --lora_alpha 44 --augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SY4YHTyVav20"
      },
      "outputs": [],
      "source": [
        "!python finetune.py --img_height 256 --img_width 256 --batch_size 1 --num_epochs 2 --ema 0 --lora --mp --pretrained_ckpt 'ckpt_epochs_1_res_256_mp_False.h5' --lora_rank 6 --lora_alpha 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5qrxX1sGnAS"
      },
      "outputs": [],
      "source": [
        "!python inference.py --prompt \"an image of a 2011 Casual Fall Green Women's Shirt\" --batch_size 3 --lora --lora_rank 4 --lora_alpha 8 --checkpoint 'lr5e05_ckpt_epochs_1_res_256_mp_False_lora_1.h5'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage import io\n",
        "from torchmetrics.image.fid import FrechetInceptionDistance\n",
        "from torchvision.transforms import functional as F\n",
        "import torch"
      ],
      "metadata": {
        "id": "5PcY1nW8Dk0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"resize_imgs/test_dataset.csv\")"
      ],
      "metadata": {
        "id": "MvVpb-5VEO-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_csv_and_return_pairs(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    if 'caption' not in df.columns or 'image_path' not in df.columns:\n",
        "        raise ValueError(\"CSV does not contain 'k' and 'v' columns\")\n",
        "\n",
        "    pairs = df.sample(5, random_state = 41)\n",
        "\n",
        "    return pairs.to_dict('records')\n",
        "\n",
        "test_images = read_csv_and_return_pairs(\"resize_imgs/test_dataset.csv\")\n",
        "test_images"
      ],
      "metadata": {
        "id": "_i0lwMkhNxh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_ims = []\n",
        "for i in range(3):\n",
        "  real_im = io.imread('resize_imgs/' + test_images[i]['image_path'])\n",
        "  real_ims.append(real_im)\n",
        "  plt.imshow(real_im)\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "Q7XTjmb0Nym4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teNVrObaC1oh"
      },
      "outputs": [],
      "source": [
        "def read_csv_and_return_pairs(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    if 'caption' not in df.columns or 'image_path' not in df.columns:\n",
        "        raise ValueError(\"CSV does not contain 'k' and 'v' columns\")\n",
        "\n",
        "    pairs = df.sample(5, random_state = 41)\n",
        "\n",
        "    return pairs.to_dict('records')\n",
        "\n",
        "test_images = read_csv_and_return_pairs(\"resize_imgs/test_dataset.csv\")\n",
        "test_images\n",
        "\n",
        "base_images = []\n",
        "for i in range(3):\n",
        "  prompt = test_images[i]['caption']\n",
        "\n",
        "  print(prompt)\n",
        "  base_model = keras_cv.models.StableDiffusion(\n",
        "      img_height=256, img_width=256\n",
        "  )\n",
        "\n",
        "  base_im_i = base_model.text_to_image(\n",
        "      prompt=prompt,\n",
        "      num_steps=50,\n",
        "      batch_size=1\n",
        "  )\n",
        "  base_images.append(base_im_i)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_images(images):\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    for i in range(len(images)):\n",
        "        ax = plt.subplot(1, len(images), i + 1)\n",
        "        plt.imshow(images[i][0])\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "plot_images(base_images)"
      ],
      "metadata": {
        "id": "xyJuaCfcHJ72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "real_ims = []\n",
        "for i in range(3):\n",
        "  real_im = io.imread('resize_imgs/' + test_images[i]['image_path'])\n",
        "  real_ims.append(real_im)\n",
        "\n",
        "\n",
        "\n",
        "def preprocess_image(image):\n",
        "\n",
        "    image = torch.tensor(image).unsqueeze(0)\n",
        "    image = image.permute(0, 3, 1, 2) / 255.0\n",
        "    return F.center_crop(image, (256, 256))\n",
        "\n",
        "\n",
        "real_images = torch.cat([preprocess_image(real_im) for real_im in real_ims])\n",
        "print(real_images.shape)\n",
        "\n",
        "base_imgs = torch.cat([preprocess_image(base_i[0]) for base_i in base_images])\n",
        "fid = FrechetInceptionDistance(normalize=True)\n",
        "fid.update(real_images, real=True)\n",
        "fid.update(base_imgs, real=False)\n",
        "\n",
        "print(f\"FID: {float(fid.compute())}\")\n"
      ],
      "metadata": {
        "id": "8mSuU5_cEFCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_with_fid.py --batch_size 3 --lora --lora_rank 4 --lora_alpha 8 --checkpoint 'ckpt_epochs_9_res_256_mp_False_lr_5e-05_epochs_10_cont.h5'"
      ],
      "metadata": {
        "id": "NkU7FBNKIp-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxK-B7MjCvmv"
      },
      "outputs": [],
      "source": [
        "PROMPT = \"an image of a 2011 Casual Fall Black Women's Jacket\"\n",
        "# Load your stable diffusion model\n",
        "original_model = keras_cv.models.StableDiffusion(\n",
        "    img_width=256, img_height=256\n",
        ")\n",
        "images_original = original_model.text_to_image(PROMPT, batch_size=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9CNe99PcGKF"
      },
      "outputs": [],
      "source": [
        "def plot_images(images):\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    for i in range(len(images)):\n",
        "        ax = plt.subplot(1, len(images), i + 1)\n",
        "        plt.imshow(images[i])\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "\n",
        "plot_images(images_original)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edAnzq27DFII"
      },
      "outputs": [],
      "source": [
        "images = model.text_to_image(\"a maroon strapless top\", batch_size=3)\n",
        "\n",
        "\n",
        "def plot_images(images):\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    for i in range(len(images)):\n",
        "        ax = plt.subplot(1, len(images), i + 1)\n",
        "        plt.imshow(images[i])\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "\n",
        "plot_images(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhWMNy4N7-Oz"
      },
      "outputs": [],
      "source": [
        "PROMPT = \"a green t-shirt\"\n",
        "BATCH_SIZE = 3\n",
        "img_width = img_height = 256\n",
        "original_model = keras_cv.models.StableDiffusion(\n",
        "    img_width=img_width, img_height=img_height\n",
        ")\n",
        "images_original = original_model.text_to_image(PROMPT, batch_size=BATCH_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9JZ5Lsj8b_i"
      },
      "outputs": [],
      "source": [
        "plot_images(images_original, \"original\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpRuhoZAv5X8"
      },
      "outputs": [],
      "source": [
        "PROMPT = \"a 2009 t-shirt\"\n",
        "BATCH_SIZE = 3\n",
        "\n",
        "images_finetuned = fashion_model.text_to_image(PROMPT, batch_size=BATCH_SIZE)\n",
        "\n",
        "\n",
        "plot_images(images_finetuned, \"finetuned\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFTPfyqGxqOw"
      },
      "outputs": [],
      "source": [
        "weights_path = keras.utils.get_file(\n",
        "    origin=\"https://huggingface.co/sayakpaul/kerascv_sd_pokemon_finetuned/resolve/main/ckpt_epochs_72_res_512_mp_True.h5\"\n",
        ")\n",
        "\n",
        "img_height = img_width = 256\n",
        "pokemon_model = keras_cv.models.StableDiffusion(\n",
        "    img_width=img_width, img_height=img_height\n",
        ")\n",
        "pokemon_model.diffusion_model.load_weights(weights_path, by_name=True, skip_mismatch=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vf3mgvDwz4n"
      },
      "outputs": [],
      "source": [
        "!python inference.py --prompt \"a pink strapless top\" --img_height 256 --img_width 256 --batch_size 1 --checkpoint 'ckpt_epochs_20_res_256_mp_False.h5' --num_steps 20"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}